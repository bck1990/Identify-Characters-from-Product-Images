{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook contains the code for scraping image from Google to add to the training set, with instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import http.cookiejar\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all labels from the folder name of the train directory (uploaded in the zip folder for this code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [name for name in os.listdir(\"./train/\")]\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each label category, search the label name in Google and put the scrape for the search result images. Then the code put these images into folders with the appropriate label names just like in the given train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url,header):\n",
    "    return BeautifulSoup(urllib.request.urlopen(urllib.request.Request(url,headers=header)),'html.parser')\n",
    "\n",
    "for category in categories:\n",
    "\n",
    "    raw_query = category + \" shirt doll\" # you can change the query for the image  here\n",
    "    image_type=\"ActiOn\"\n",
    "    query= raw_query.split()\n",
    "    query='+'.join(query)\n",
    "    url=\"https://www.google.com/search?q=\"+query+\"&source=lnms&tbm=isch\"\n",
    "    print(url)\n",
    "    #directory for image\n",
    "    DIR=\"expand_train_set_shirt_doll\"\n",
    "    header={'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"\n",
    "    }\n",
    "    soup = get_soup(url,header)\n",
    "\n",
    "\n",
    "    ActualImages=[]# contains the link for Large original images, type of  image\n",
    "    for a in soup.find_all(\"div\",{\"class\":\"rg_meta\"}):\n",
    "        link , Type =json.loads(a.text)[\"ou\"]  ,json.loads(a.text)[\"ity\"]\n",
    "        ActualImages.append((link,Type))\n",
    "\n",
    "    print(\"For \" + raw_query + \", there are a total of \" + str(len(ActualImages)) + \" images.\")\n",
    "\n",
    "    if not os.path.exists(DIR):\n",
    "                os.mkdir(DIR)\n",
    "    DIR = os.path.join(DIR, category)\n",
    "\n",
    "    if not os.path.exists(DIR):\n",
    "                os.mkdir(DIR)\n",
    "\n",
    "    DIR = DIR + \"/\"\n",
    "\n",
    "    print(DIR)\n",
    "\n",
    "    ###print images\n",
    "    for i, (img , Type) in enumerate( ActualImages):\n",
    "        try:\n",
    "            r = requests.get(img, allow_redirects=True)\n",
    "            if not Type:\n",
    "                print(\"No type.\")\n",
    "            else:\n",
    "                open(DIR + str(i) + \".\" + Type, 'wb').write(r.content)\n",
    "                print(\"Saving \" + img)\n",
    "            #print(img,Type)\n",
    "            #print()\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"could not load : \"+img)\n",
    "            print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After running this code, I manually copied both the original train images and these additional images into a new folder called 'train_expanded_characters' which is included in the uploaded zip folder. \n",
    "\n",
    "### Note that the images for 'ben' are ignored as they contain too many irrelevant photos of people named 'ben'.\n",
    "\n",
    "### Also note that it is better to modify the code to search for 'Goku' before manually renaming the folder to the label 'Goku_1' as 'Goku_1' is not a good search term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
